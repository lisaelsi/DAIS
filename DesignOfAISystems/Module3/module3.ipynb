{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random as rand\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Read data\n",
    "data_beijing = pd.read_csv('Cities/Beijing_labeled.csv')\n",
    "data_shanghai = pd.read_csv('Cities/Shanghai_labeled.csv')\n",
    "data_chengdu = pd.read_csv('Cities/Chengdu_labeled.csv')\n",
    "data_shenyang = pd.read_csv('Cities/Shenyang_labeled.csv')\n",
    "data_guanzhou = pd.read_csv('Cities/Guangzhou_labeled.csv')\n",
    "\n",
    "test_data_guanzhou = data_guanzhou\n",
    "test_data_shanghai = data_shanghai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_beijing.append(data_shenyang, ignore_index = True)\n",
    "\n",
    "X_train = train_data.loc[:, train_data.columns != 'PM_HIGH']\n",
    "Y_train = train_data.loc[:,\"PM_HIGH\"]\n",
    "\n",
    "X_test_guangzhou = test_data_guanzhou.loc[:, test_data_guanzhou.columns != 'PM_HIGH']\n",
    "Y_test_guangzhou = test_data_guanzhou.loc[:,\"PM_HIGH\"]\n",
    "\n",
    "X_test_shanghai = test_data_shanghai.loc[:, test_data_shanghai.columns != 'PM_HIGH']\n",
    "Y_test_shanghai = test_data_shanghai.loc[:,\"PM_HIGH\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Undersampling training data**\\\n",
    "In our training data set the majority class for the target variable is 0. Here, we use undersampling to create a balanced data set. We get a data set with 1564 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices of all 'ones' from training data\n",
    "ones_inds = train_data.loc[train_data['PM_HIGH'] == 1].index.to_list()\n",
    "number_of_ones = len(ones_inds)\n",
    "\n",
    "# Get indices of all 'zeros' from training data \n",
    "zeros_inds = train_data.loc[train_data['PM_HIGH'] == 0].index.tolist()\n",
    "\n",
    "# Select a random subset of 'zeros', the same number as the number of 'ones' \n",
    "random_zeros = rand.sample(zeros_inds, number_of_ones)\n",
    "\n",
    "# Combine indices of all of the original 'ones', and the selected 'zeros'\n",
    "undersampling_inds = ones_inds + random_zeros\n",
    "undersampled_data = train_data.iloc[undersampling_inds]\n",
    "\n",
    "# Shuffle the data\n",
    "undersampled_data = undersampled_data.sample(frac=1)\n",
    " \n",
    "# Split into X and Y\n",
    "X_train_undersampled = undersampled_data.loc[:, undersampled_data.columns != 'PM_HIGH']\n",
    "Y_train_undersampled = undersampled_data.loc[:,\"PM_HIGH\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oversampling training data**\\\n",
    "In our training data set the majority class for the target variable is 0. Here, we use oversampling to create a balanced data set. We get a data set with 5280 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the 'ones' from the training data\n",
    "ones =  train_data.loc[train_data['PM_HIGH'] == 1]\n",
    "ones_copy = ones.copy()\n",
    "\n",
    "# Triple the 'ones' we had from the beginning\n",
    "train_data_extra_ones = train_data.append(ones_copy, ignore_index = True)\n",
    "train_data_extra_ones = train_data_extra_ones.append(ones_copy, ignore_index = True)\n",
    "\n",
    "# Get 1858 indices of 'ones' so that we have the same amount of 'ones' as 'zeros'\n",
    "extra_ones_inds = train_data_extra_ones.loc[train_data_extra_ones['PM_HIGH'] == 1].index.tolist()\n",
    "rand_extra_ones = rand.sample(extra_ones_inds, 1858)\n",
    "\n",
    "# Combine indices of all of the original 'ones', 'zeros' and the extra 'ones'\n",
    "oversampling_inds = ones_inds + zeros_inds + rand_extra_ones\n",
    "oversampled_data = train_data_extra_ones.iloc[oversampling_inds]\n",
    "\n",
    "# Shuffle the data\n",
    "oversampled_data = oversampled_data.sample(frac=1)\n",
    "\n",
    "# Split into X and Y\n",
    "X_train_oversampled = oversampled_data.loc[:, oversampled_data.columns != 'PM_HIGH']\n",
    "Y_train_oversampled = oversampled_data.loc[:,\"PM_HIGH\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oversampling the test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "# Create oversampler\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "\n",
    "# Oversample data for both shanghai and guangzhou\n",
    "X_test_oversampled_shanghai, Y_test_oversampled_shanghai = oversample.fit_resample(X_test_shanghai, Y_test_shanghai)\n",
    "X_test_oversampled_guangzhou, Y_test_oversampled_guangzhou = oversample.fit_resample(X_test_guangzhou, Y_test_guangzhou)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling the data**\\\n",
    "The features in the data set are of different magnitude. We are measuring distances, and want all features to be treated equally - all features should have the same impact on the distance calculation. Therefore, we scale the data using the min max scaler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_oversampled\n",
    "Y_train = Y_train_oversampled \n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled_shanghai = scaler.transform(X_test_oversampled_shanghai)\n",
    "X_test_scaled_guangzhou = scaler.transform(X_test_oversampled_guangzhou)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create KMeans Classifier**Â \\\n",
    "Our classifier, implemented with KMeans from sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class KMeansClassifier:\n",
    "\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        # The Y-value for each centroid\n",
    "        self.centroid_y = []\n",
    "        # The centroid coordinates\n",
    "        self.centroid_centers = []\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "\n",
    "        # Fit SKLearns KMeans clustering\n",
    "        kmeans = KMeans(n_clusters = self.k, n_init='auto')\n",
    "        kmeans.fit(X)\n",
    "        \n",
    "        # Get the centroid centers\n",
    "        self.centroid_centers = kmeans.cluster_centers_ \n",
    "\n",
    "        # Get what datapoints belong to which cluster\n",
    "        point_belongs_to = kmeans.labels_\n",
    "\n",
    "\n",
    "        for centroid_i in range(self.k):\n",
    "\n",
    "            # Indices of all datapoints belonging to centroid i\n",
    "            index_centroid_i = np.where(point_belongs_to == centroid_i)\n",
    "            \n",
    "            # All the Y-values of datapoints in centroid i\n",
    "            y_values_centroid_i = Y.iloc[index_centroid_i]\n",
    "\n",
    "            # The most frequent Y-value in centroid i\n",
    "            most_frequent_y = y_values_centroid_i.value_counts().idxmax()\n",
    "\n",
    "            self.centroid_y.append(most_frequent_y)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for datapoint in X:\n",
    "\n",
    "            # The index of the closest centroid\n",
    "            closest_centroid = pairwise_distances_argmin([datapoint], self.centroid_centers)\n",
    "\n",
    "            # The Y-value of the the closest centroid\n",
    "            y_value = self.centroid_y[closest_centroid[0]]\n",
    "            predictions.append(y_value)\n",
    "        \n",
    "        return predictions\n",
    "        \n",
    "\n",
    "    def score(self, x, y):\n",
    "        predictions  = self.predict(x)\n",
    "\n",
    "        # Calculate accuary\n",
    "        acc = accuracy_score(y, predictions)\n",
    "        return acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross-validation**\\\n",
    "Using cross-validation with 5 folds to identify the number of clusters that gives the best performance on our training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of each fold: [0.5499474237644585, 0.5709779179810726, 0.5720294426919033, 0.5621052631578948, 0.5368421052631579]\n",
      "f1 score of each fold: [0.7096336499321574, 0.7269076305220884, 0.7277591973244147, 0.7196765498652291, 0.6986301369863014]\n",
      "Avg accuracy: 0.5583804305716974 for k = 1\n",
      "Avg f1 score: 0.7165214329260382 for k = 1\n",
      "\n",
      "\n",
      "Accuracy of each fold: [0.5930599369085173, 0.40904311251314407, 0.61198738170347, 0.5978947368421053, 0.42105263157894735]\n",
      "f1 score of each fold: [0.5251533742331288, 0.5339966832504145, 0.6392961876832844, 0.6225296442687748, 0.4488977955911823]\n",
      "Avg accuracy: 0.5266075599092368 for k = 2\n",
      "Avg f1 score: 0.553974737005357 for k = 2\n",
      "\n",
      "\n",
      "Accuracy of each fold: [0.6466876971608833, 0.49631966351209256, 0.40904311251314407, 0.38526315789473686, 0.5168421052631579]\n",
      "f1 score of each fold: [0.7345971563981043, 0.5317693059628543, 0.5277310924369747, 0.5008547008547009, 0.6066838046272494]\n",
      "Avg accuracy: 0.49083114726880295 for k = 3\n",
      "Avg f1 score: 0.5803272120559766 for k = 3\n",
      "\n",
      "\n",
      "Accuracy of each fold: [0.6540483701366983, 0.33964248159831756, 0.38485804416403785, 0.6884210526315789, 0.6189473684210526]\n",
      "f1 score of each fold: [0.720949957591179, 0.3757455268389663, 0.3743315508021391, 0.7529215358931552, 0.7085346215780999]\n",
      "Avg accuracy: 0.5371834633903371 for k = 4\n",
      "Avg f1 score: 0.586496638540708 for k = 4\n",
      "\n",
      "\n",
      "Accuracy of each fold: [0.6572029442691903, 0.3890641430073607, 0.4931650893796004, 0.5157894736842106, 0.41578947368421054]\n",
      "f1 score of each fold: [0.6746506986027944, 0.42532146389713155, 0.5452830188679245, 0.5643939393939393, 0.4307692307692308]\n",
      "Avg accuracy: 0.4942022248049146 for k = 5\n",
      "Avg f1 score: 0.5280836703062042 for k = 5\n",
      "\n",
      "\n",
      "Accuracy of each fold: [0.6540483701366983, 0.47528916929547843, 0.5289169295478444, 0.5231578947368422, 0.5547368421052632]\n",
      "f1 score of each fold: [0.720949957591179, 0.5634295713035871, 0.6516329704510109, 0.6361445783132531, 0.6192619261926192]\n",
      "Avg accuracy: 0.5472298411644253 for k = 6\n",
      "Avg f1 score: 0.6382838007703299 for k = 6\n",
      "\n",
      "\n",
      "Accuracy of each fold: [0.6540483701366983, 0.4069400630914827, 0.47213459516298634, 0.5863157894736842, 0.4557894736842105]\n",
      "f1 score of each fold: [0.720949957591179, 0.49552772808586765, 0.4803312629399586, 0.6537444933920705, 0.5312783318223028]\n",
      "Avg accuracy: 0.5150456583098124 for k = 7\n",
      "Avg f1 score: 0.5763663547662757 for k = 7\n",
      "\n",
      "\n",
      "Accuracy of each fold: [0.6540483701366983, 0.4332281808622503, 0.4815983175604627, 0.38105263157894737, 0.46842105263157896]\n",
      "f1 score of each fold: [0.720949957591179, 0.464746772591857, 0.49847405900305186, 0.3875, 0.48205128205128206]\n",
      "Avg accuracy: 0.48366971055398744 for k = 8\n",
      "Avg f1 score: 0.510744414247474 for k = 8\n",
      "\n",
      "\n",
      "Accuracy of each fold: [0.6540483701366983, 0.49631966351209256, 0.5888538380651945, 0.5747368421052632, 0.5789473684210527]\n",
      "f1 score of each fold: [0.720949957591179, 0.592340425531915, 0.6677994902293968, 0.6644518272425248, 0.6261682242990654]\n",
      "Avg accuracy: 0.5785812164480603 for k = 9\n",
      "Avg f1 score: 0.6543419849788161 for k = 9\n",
      "\n",
      "\n",
      "Accuracy of each fold: [0.6540483701366983, 0.5457413249211357, 0.4490010515247108, 0.5778947368421052, 0.588421052631579]\n",
      "f1 score of each fold: [0.720949957591179, 0.5772994129158513, 0.5009523809523809, 0.6248830682881198, 0.6207565470417071]\n",
      "Avg accuracy: 0.5630213072112458 for k = 10\n",
      "Avg f1 score: 0.6089682733578476 for k = 10\n",
      "\n",
      "\n",
      "Accuracy of each fold: [0.676130389064143, 0.48264984227129337, 0.45531019978969506, 0.6294736842105263, 0.4126315789473684]\n",
      "f1 score of each fold: [0.7169117647058824, 0.4533333333333333, 0.44181034482758624, 0.6615384615384616, 0.3496503496503497]\n",
      "Avg accuracy: 0.5312391388566052 for k = 11\n",
      "Avg f1 score: 0.5246488508111227 for k = 11\n",
      "\n",
      "\n",
      "Accuracy of each fold: [0.676130389064143, 0.3890641430073607, 0.4784437434279706, 0.5905263157894737, 0.4789473684210526]\n",
      "f1 score of each fold: [0.7169117647058824, 0.40653728294177727, 0.5221579961464355, 0.6312796208530806, 0.4794952681388013]\n",
      "Avg accuracy: 0.5226223919420001 for k = 12\n",
      "Avg f1 score: 0.5512763865571955 for k = 12\n",
      "\n",
      "\n",
      "Accuracy of each fold: [0.6740273396424816, 0.49631966351209256, 0.4637223974763407, 0.3831578947368421, 0.5210526315789473]\n",
      "f1 score of each fold: [0.714548802946593, 0.5672990063233966, 0.5067698259187621, 0.3831578947368421, 0.5445445445445446]\n",
      "Avg accuracy: 0.5076559853893409 for k = 13\n",
      "Avg f1 score: 0.5432640148940278 for k = 13\n",
      "\n",
      "\n",
      "Accuracy of each fold: [0.6740273396424816, 0.5184016824395373, 0.5878023133543638, 0.4631578947368421, 0.42947368421052634]\n",
      "f1 score of each fold: [0.714548802946593, 0.57196261682243, 0.6487455197132616, 0.4806517311608961, 0.41594827586206895]\n",
      "Avg accuracy: 0.5345725828767502 for k = 14\n",
      "Avg f1 score: 0.56637138930105 for k = 14\n",
      "\n",
      "\n",
      "Accuracy of each fold: [0.6740273396424816, 0.5425867507886435, 0.5930599369085173, 0.6031578947368421, 0.6252631578947369]\n",
      "f1 score of each fold: [0.714548802946593, 0.6147032772364925, 0.6535362578334826, 0.6473339569691301, 0.667910447761194]\n",
      "Avg accuracy: 0.6076190159942442 for k = 15\n",
      "Avg f1 score: 0.6596065485493784 for k = 15\n",
      "\n",
      "\n",
      "Accuracy of each fold: [0.7055730809674028, 0.4500525762355415, 0.5436382754994742, 0.608421052631579, 0.531578947368421]\n",
      "f1 score of each fold: [0.7582037996545768, 0.5266968325791856, 0.6226086956521739, 0.6574585635359116, 0.5797922568460813]\n",
      "Avg accuracy: 0.5678527865404838 for k = 16\n",
      "Avg f1 score: 0.6289520296535859 for k = 16\n",
      "\n",
      "\n",
      "Accuracy of each fold: [0.6982124079915878, 0.5888538380651945, 0.4658254468980021, 0.4189473684210526, 0.48947368421052634]\n",
      "f1 score of each fold: [0.745792736935341, 0.6638005159071366, 0.50390625, 0.46093750000000006, 0.5286686103012633]\n",
      "Avg accuracy: 0.5322625491172727 for k = 17\n",
      "Avg f1 score: 0.5806211226287482 for k = 17\n",
      "\n",
      "\n",
      "Accuracy of each fold: [0.7024185068349106, 0.5415352260778128, 0.4395373291272345, 0.5747368421052632, 0.5305263157894737]\n",
      "f1 score of each fold: [0.7502206531332745, 0.6141592920353982, 0.5253784505788067, 0.6340579710144928, 0.5974729241877257]\n",
      "Avg accuracy: 0.5577508439869389 for k = 18\n",
      "Avg f1 score: 0.6242578581899395 for k = 18\n",
      "\n",
      "\n",
      "Accuracy of each fold: [0.6992639327024185, 0.5856992639327024, 0.573080967402734, 0.4231578947368421, 0.5631578947368421]\n",
      "f1 score of each fold: [0.7441860465116279, 0.6254752851711027, 0.6103646833013436, 0.4267782426778243, 0.5820745216515609]\n",
      "Avg accuracy: 0.5688719907023078 for k = 19\n",
      "Avg f1 score: 0.5977757558626919 for k = 19\n",
      "\n",
      "\n",
      "Accuracy of each fold: [0.7034700315457413, 0.5783385909568874, 0.5320715036803365, 0.4473684210526316, 0.4263157894736842]\n",
      "f1 score of each fold: [0.7491103202846976, 0.6731866340668297, 0.6016114592658908, 0.4847890088321884, 0.49490268767377205]\n",
      "Avg accuracy: 0.5375128673418562 for k = 20\n",
      "Avg f1 score: 0.6007200220246757 for k = 20\n",
      "\n",
      "\n",
      "Accuracy of each fold: [0.704521556256572, 0.4952681388012618, 0.5415352260778128, 0.5684210526315789, 0.5431578947368421]\n",
      "f1 score of each fold: [0.7515473032714413, 0.5737122557726466, 0.6221837088388215, 0.6483704974271012, 0.6232638888888888]\n",
      "Avg accuracy: 0.5705807737008135 for k = 21\n",
      "Avg f1 score: 0.6438155308397799 for k = 21\n",
      "\n",
      "\n",
      "Accuracy of each fold: [0.7150368033648791, 0.6004206098843323, 0.5751840168243953, 0.52, 0.4378947368421053]\n",
      "f1 score of each fold: [0.7573858549686661, 0.6838602329450915, 0.6535162950257289, 0.5777777777777778, 0.4723320158102767]\n",
      "Avg accuracy: 0.5697072333831424 for k = 22\n",
      "Avg f1 score: 0.6289744353055082 for k = 22\n",
      "\n",
      "\n",
      "Accuracy of each fold: [0.6908517350157729, 0.5120925341745531, 0.45846477392218715, 0.5210526315789473, 0.5168421052631579]\n",
      "f1 score of each fold: [0.7317518248175181, 0.5547024952015356, 0.5062320230105465, 0.5687203791469194, 0.534010152284264]\n",
      "Avg accuracy: 0.5398607559909236 for k = 23\n",
      "Avg f1 score: 0.5790833748921568 for k = 23\n",
      "\n",
      "\n",
      "Accuracy of each fold: [0.6982124079915878, 0.4868559411146162, 0.5057833859095688, 0.48526315789473684, 0.5378947368421053]\n",
      "f1 score of each fold: [0.7448888888888888, 0.5571687840290381, 0.584070796460177, 0.5614349775784754, 0.5830959164292498]\n",
      "Avg accuracy: 0.542801925950523 for k = 24\n",
      "Avg f1 score: 0.6061318726771658 for k = 24\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Number of folds\n",
    "k = 5\n",
    "kfold = KFold(k, shuffle=False)\n",
    "\n",
    "plot_acc_scores = []\n",
    "\n",
    "for i in range(1,25):\n",
    "\n",
    "    clf = KMeansClassifier(i)\n",
    "    acc_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_index, test_index in kfold.split(X_train_scaled):\n",
    "\n",
    "        # Split into train and test sets based on the KFold\n",
    "        X_train, X_test = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "        y_train, y_test = Y_train.iloc[train_index], Y_train.iloc[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        predicted_values = clf.predict(X_test)\n",
    "        \n",
    "        acc = accuracy_score(y_test, predicted_values)\n",
    "        acc_scores.append(acc)\n",
    "        avg_acc_score = sum(acc_scores)/k\n",
    "\n",
    "        f1 = f1_score(y_test, predicted_values)\n",
    "        f1_scores.append(f1)\n",
    "        avg_f1_score = sum(f1_scores)/k\n",
    "    \n",
    "    plot_acc_scores.append(avg_acc_score)\n",
    "    \n",
    "    print('Accuracy of each fold: {}'.format(acc_scores))\n",
    "    print('f1 score of each fold: {}'.format(f1_scores))\n",
    "    print('Avg accuracy: {} for k = {}'.format(avg_acc_score, i))\n",
    "    print('Avg f1 score: {} for k = {}'.format(avg_f1_score, i))\n",
    "    print('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From performing the cross-validation, we selected 5 as the number of clusters to use. \n",
    "\n",
    "Here, we are training the classifier with the selected number of clusters and calculating first the accuracy, and then the f1 score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for Shanghai test set: 0.3929\n",
      "Accuracy score for Guangzhou test set: 0.5075\n"
     ]
    }
   ],
   "source": [
    "clf = KMeansClassifier(5)\n",
    "\n",
    "# Shanghai\n",
    "clf.fit(X_train_scaled, Y_train)\n",
    "score = clf.score(X_test_scaled_shanghai, Y_test_oversampled_shanghai)\n",
    "print('Accuracy score for Shanghai test set:', round(score, 4))\n",
    "\n",
    "# Guangzhou\n",
    "score = clf.score(X_test_scaled_guangzhou, Y_test_oversampled_guangzhou)\n",
    "print('Accuracy score for Guangzhou test set:', round(score, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score for Shanghai test set: 0.2609\n",
      "f1 score for Guangzhou test set: 0.4528\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Shanghai\n",
    "predicted_y_shanghai = clf.predict(X_test_scaled_shanghai)\n",
    "f1_shanghai = f1_score(Y_test_oversampled_shanghai, predicted_y_shanghai)\n",
    "print('f1 score for Shanghai test set:', round(f1_shanghai, 4))\n",
    "\n",
    "# Guangzhou\n",
    "predicted_y_guangzhou = clf.predict(X_test_scaled_guangzhou)\n",
    "f1 = f1_score(Y_test_oversampled_guangzhou, predicted_y_guangzhou)\n",
    "print('f1 score for Guangzhou test set:', round(f1, 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we noticed that we got a low f1 score, we decided to plot the confusion matrix for the test set. This shows that there are quite many zeros that get misclassified as ones.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix for test set Guangzhou\n",
    "\n",
    "confusion_matrix_guangzhou = metrics.confusion_matrix(Y_test_oversampled_guangzhou, predicted_y_guangzhou)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_guangzhou, display_labels = [0, 1])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix for test set Shanghai\n",
    "\n",
    "confusion_matrix_shanghai = metrics.confusion_matrix(Y_test_oversampled_shanghai, predicted_y_shanghai)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_shanghai, display_labels = [0, 1])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing with logistic regression and KNN**\\\n",
    "We are examining the performances of the models logistic regression and KNN, to be able to compare the performance of our model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of logistic regression for test set Shanghai: 0.4573\n",
      "F1 Score of logistic regression for test set Shanghai: 0.4302 \n",
      "\n",
      "Accuracy score of KNN Classifier for test set Shanghai: 0.5378\n",
      "F1 score of KNN Classifier for test set Shanghai: 0.6149\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression()\n",
    "lgr.fit(X_train_scaled, Y_train)\n",
    "lgr_score = lgr.score(X_test_scaled_shanghai, Y_test_oversampled_shanghai)\n",
    "lgr_predictions = lgr.predict(X_test_scaled_shanghai)\n",
    "f1_lgr = f1_score(Y_test_oversampled_shanghai, lgr_predictions)\n",
    "print(f'Accuracy score of logistic regression for test set Shanghai: {round(lgr_score, 4)}')\n",
    "print(f'F1 Score of logistic regression for test set Shanghai: {round(f1_lgr, 4)} \\n')\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_scaled, Y_train)\n",
    "knn_score = knn.score(X_test_scaled_shanghai, Y_test_oversampled_shanghai)\n",
    "knn_predictions = knn.predict(X_test_scaled_shanghai)\n",
    "f1_knn = f1_score(Y_test_oversampled_shanghai, knn_predictions)\n",
    "print('Accuracy score of KNN Classifier for test set Shanghai:', round(knn_score, 4))\n",
    "print('F1 score of KNN Classifier for test set Shanghai:', round(f1_knn, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of logistic regression for test set Guangzhou: 0.5296\n",
      "F1 Score of logistic regression for test set Guangzhou: 0.5733 \n",
      "\n",
      "Accuracy score of KNN Classifier for test set Guangzhou: 0.481\n",
      "F1 score of KNN Classifier for test set Guangzhou: 0.5761\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression()\n",
    "lgr.fit(X_train_scaled, Y_train)\n",
    "lgr_score = lgr.score(X_test_scaled_guangzhou, Y_test_oversampled_guangzhou)\n",
    "lgr_predictions = lgr.predict(X_test_scaled_guangzhou)\n",
    "f1_lgr = f1_score(Y_test_oversampled_guangzhou, lgr_predictions)\n",
    "print('Accuracy score of logistic regression for test set Guangzhou:', round(lgr_score, 4))\n",
    "print(f'F1 Score of logistic regression for test set Guangzhou: {round(f1_lgr, 4)} \\n')\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_scaled, Y_train)\n",
    "knn_score = knn.score(X_test_scaled_guangzhou, Y_test_oversampled_guangzhou)\n",
    "knn_predictions = knn.predict(X_test_scaled_guangzhou)\n",
    "f1_knn = f1_score(Y_test_oversampled_guangzhou, knn_predictions)\n",
    "print('Accuracy score of KNN Classifier for test set Guangzhou:', round(knn_score, 4))\n",
    "print('F1 score of KNN Classifier for test set Guangzhou:', round(f1_knn, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3e2c82196e12baaed2ed09f9a042bc281a80ecc12c17ec56f626fcbf6ffbb0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
